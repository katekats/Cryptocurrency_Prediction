{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Insert the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "import pandas as pd\n",
    "from scipy import integrate\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import re\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import logging\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download price data, tweets and tweets metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the data\n",
    "\n",
    "prices_df = pd.read_csv(\"Downloads/pricesfeb-apr15_usdt.csv\", low_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the data\n",
    "\n",
    "#prices_df = pd.read_csv(\"Downloads/pricesfeb-apr15_usdt.csv\", low_memory=True)\n",
    "\n",
    "tweets_metadata_df = pd.read_csv(\"Downloads/tweets_metadata10052021.csv\")\n",
    "\n",
    "tweets_df = pd.read_csv(\"Downloads/tweets_filled_gaps.csv\", low_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions for computing vader score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger()\n",
    "sent_analyzer = None\n",
    "\n",
    "\n",
    "# Text Cleaning Methods\n",
    "# Source: https://medium.com/@datamonsters/text-preprocessing-in-python-steps-tools-and-examples-bf025f872908\n",
    "# To-Lower-Case-method not suitable --> Vader needs cap letters for score balancing\n",
    "# Remove-Punctuation-method not suitable --> Vader needs punctuation for score balancing\n",
    "# Tokenization etc. not suitable --> Vader needs sentence structure for score balancing\n",
    "\n",
    "def replace_url(text):\n",
    "    \"\"\" Replaces url address with \"url\" \"\"\"\n",
    "    text = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))', 'url', text)\n",
    "    text = re.sub(r'#([^\\s]+)', r'\\1', text)\n",
    "    return text\n",
    "\n",
    "\n",
    "def replace_at_user(text):\n",
    "    \"\"\" Replaces \"@user\" with \"atUser\" \"\"\"\n",
    "    text = re.sub('@[^\\s]+', 'atUser', text)\n",
    "    return text\n",
    "\n",
    "\n",
    "def remove_unicode(text):\n",
    "    \"\"\" Removes unicode from tweet \"\"\"\n",
    "    text = re.sub(r'(\\\\u[0-9A-Fa-f]+)', r'', text)\n",
    "    text = re.sub(r'[^\\x00-\\x7f]', r'', text)\n",
    "    return text\n",
    "\n",
    "\n",
    "def remove_hashtag_in_front_of_word(text):\n",
    "    \"\"\" Removes hastag-sign in front of a word \"\"\"\n",
    "    text = re.sub(r'#([^\\s]+)', r'\\1', text)\n",
    "    return text\n",
    "\n",
    "\n",
    "def leave_hash_tag_only(text):\n",
    "    \"\"\" Leaves only hashtags that are present in tweet \"\"\"\n",
    "    text = re.findall(r\"#(\\w+)\", text)\n",
    "    return text\n",
    "\n",
    "\n",
    "def remove_numbers(text):\n",
    "    \"\"\" Removes numerical chars \"\"\"\n",
    "    text = ''.join([i for i in text if not i.isdigit()])\n",
    "    return text\n",
    "\n",
    "\n",
    "def custom_stop_words(text):\n",
    "    \"\"\" Custom stop-words to be removal without changing DTYPE\"\"\"\n",
    "    text = re.sub(r'url', r'', text)\n",
    "    text = re.sub(r'nan', r'', text)\n",
    "    text = re.sub(r'\\n', r'', text)\n",
    "    return text\n",
    "\n",
    "\n",
    "def init_sent_model():\n",
    "    crypto_words = get_vader_dict()\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    analyzer.lexicon.update(crypto_words)\n",
    "    return analyzer\n",
    "\n",
    "\n",
    "def get_vader_dict():\n",
    "    crypto_words = {}\n",
    "    with open(\"vader_config.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            (key, val) = line.split(':')\n",
    "            crypto_words[key] = float(val)\n",
    "\n",
    "    return crypto_words\n",
    "\n",
    "\n",
    "# VADER sentiment analysis\n",
    "def vader_sentiment_score(text):\n",
    "    \"\"\" VADER: A Parsimonious Rule-based Model for Sentiment Analysis of Social Media Text \"\"\"\n",
    "    \"\"\" source: https://github.com/cjhutto/vaderSentiment \"\"\"\n",
    "    global sent_analyzer\n",
    "    if sent_analyzer is None:\n",
    "        sent_analyzer = init_sent_model()\n",
    "    detail_score = sent_analyzer.polarity_scores(text)\n",
    "    score = detail_score[\"compound\"]\n",
    "    return detail_score, score\n",
    "\n",
    "\n",
    "def calc_sentiment(text):\n",
    "    # Preprocess tweet / message\n",
    "    #text = remove_unicode(text) no need if we consider emoticons\n",
    "    text = replace_url(text)\n",
    "    text = replace_at_user(text)\n",
    "    text = remove_hashtag_in_front_of_word(text)\n",
    "    text = remove_numbers(text)\n",
    "    text = custom_stop_words(text)\n",
    "\n",
    "    # Score message with Vader-Sentiment\n",
    "    detail_score, score = vader_sentiment_score(text)\n",
    "\n",
    "    return score\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate the different sentiment score functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that finds the sum of the score column from the tweet_df per hour (unsing only the vader_score)\n",
    "\n",
    "def aggr_score(tweets_df):\n",
    "    tweets_df[\"created_at\"] =pd.to_datetime(tweets_df[\"created_at\"], utc=True)\n",
    "    tweets_df[\"created_at\"]= tweets_df[\"created_at\"].astype(str)\n",
    "    tweets_df[\"created_at\"] =pd.to_datetime(tweets_df[\"created_at\"].str[:-6])\n",
    "    tweets_df2 = tweets_df[tweets_df[\"created_at\"].dt.year==2021]\n",
    "    h =  tweets_df2[[\"created_at\", \"score\"]].groupby(pd.Grouper(key='created_at',freq='H')).score.sum()\n",
    "    return h\n",
    "\n",
    "# function that finds the sum of only the negative score column from the tweet_df per hour (unsing only the vader_score)\n",
    "\n",
    "def aggr_neg_score(tweets_df):\n",
    "    tweets_df[\"created_at\"] =pd.to_datetime(tweets_df[\"created_at\"], utc=True)\n",
    "    tweets_df[\"created_at\"]= tweets_df[\"created_at\"].astype(str)\n",
    "    tweets_df[\"created_at\"] =pd.to_datetime(tweets_df[\"created_at\"].str[:-6])\n",
    "    tweets_df2 = tweets_df[tweets_df[\"created_at\"].dt.year==2021]\n",
    "    h2 = tweets_df2.loc[(tweets_df2['score'] < 0 )].groupby(pd.Grouper(key='created_at',freq='H')).score.sum() \n",
    "    return h2\n",
    "\n",
    "# function that find the tweets with metadata and created a unified dataframe both with the text from tweets and the metadata\n",
    "\n",
    "def tweets_with_metadata(tweets_df, tweets_metadata_df):\n",
    "    tweets_metadata_df2 = tweets_metadata_df.sort_values('fetched_at').groupby('id').tail(1)\n",
    "    tweets_df_merge = pd.merge(tweets_df, tweets_metadata_df2[[\"id\", \"like_count\", \"reply_count\", \"retweet_count\", \"quote_count\"]], on='id', how = \"left\")\n",
    "    return tweets_df_merge\n",
    "\n",
    "\n",
    "\n",
    "#function that includes likes, retweets and quotes in the calculation of the sentiment score\n",
    "#that adds in the new column score2\n",
    "\n",
    "def sent_score_metadata(tweets_df_merge):\n",
    "    tweets_df_merge[\"score2\"] =np.where(((tweets_df_merge.like_count.notna())|(tweets_df_merge.retweet_count.notna())|(tweets_df_merge.quote_count.notna())), (tweets_df_merge.score*((tweets_df_merge.like_count)+(tweets_df_merge.retweet_count)+(tweets_df_merge.quote_count))),tweets_df_merge.score)\n",
    "    return tweets_df_merge[\"score2\"]\n",
    "\n",
    "\n",
    "# function that finds the sum of the sent_score_metadata function per hour\n",
    "def aggr_score_metadata(tweets_df_merge):\n",
    "    tweets_df_merge[\"score2\"] = sent_score_metadata(tweets_df_merge)\n",
    "    tweets_df_merge[\"created_at\"] =pd.to_datetime(tweets_df_merge[\"created_at\"], utc=True)\n",
    "    tweets_df_merge[\"created_at\"]= tweets_df_merge[\"created_at\"].astype(str)\n",
    "    tweets_df_merge[\"created_at\"] =pd.to_datetime(tweets_df_merge[\"created_at\"].str[:-6])\n",
    "    tweets_df_merge = tweets_df_merge[tweets_df_merge[\"created_at\"].dt.year==2021]\n",
    "    h8 =  tweets_df_merge.groupby(pd.Grouper(key='created_at',freq='H')).score2.sum()\n",
    "    return h8\n",
    "\n",
    "# function that uses tweets_with_metadata, sent_score_metadata, aggr_score_metadata functions\n",
    "def final_sentiment_score_with_metadata(tweets_df, tweets_metadata_df):\n",
    "    tweets_df_merge =tweets_with_metadata(tweets_df, tweets_metadata_df)\n",
    "    tweets_df_merge[score2] =sent_score_metadata(tweets_df_merge)\n",
    "    h8 = aggr_score_metadata(tweets_df_merge)\n",
    "    return h8\n",
    "    \n",
    "# function that changes the name of created_at(datetime) column of tweets_df to E, so we are compatible with price data\n",
    "# and resets index\n",
    "def process_score(x1, score):\n",
    "    x1 =x1.reset_index()\n",
    "    x1 =x1.rename(columns={'created_at':'E'})\n",
    "    x1.reset_index(drop=True, inplace=True)\n",
    "    x1b = x1[[\"E\", score]]\n",
    "    x1b= x1b.set_index(\"E\")\n",
    "    return x1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "#h = aggr_score(tweets_df)\n",
    "#h2 = aggr_neg_score(tweets_df)\n",
    "#\n",
    "#h8 = aggr_score_metadata(tweets_df_merge)\n",
    "#h_new = process_score(h8)\n",
    "\n",
    "# calculate the sentiment score in case that we don't use any metadata\n",
    "def sentiment_score_calc(function, tweets_df, score):\n",
    "    h = function(tweets_df)\n",
    "    h_new = process_score(h, score)\n",
    "    x1b_diff= time_series_stationary(h_new,\"score\")\n",
    "    \n",
    "        \n",
    "    return h_new\n",
    "\n",
    "#def final_sentiment_score_with_metadata(tweets_df, tweets_metadata_df):\n",
    "#    tweets_df_merge =tweets_with_metadata(tweets_df, tweets_metadata_df)\n",
    "#    tweets_df_merge[\"score\"] =sent_score_metadata(tweets_df_merge)\n",
    "#    h8 = aggr_score_metadata(tweets_df_merge)\n",
    "#    h_new = process_score(h8)\n",
    "#    return h_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#h = sentiment_score_calc(aggr_neg_score, tweets_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#h2 = final_sentiment_score_with_metadata(tweets_df, tweets_metadata_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Price Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function chooses the cryptocurrencies lis performs some cleaning on the price data, like removing data earlier than 2021, and create columns first, min, max, last prices per hour\n",
    "def process_prices(prices_df,coins):\n",
    "\n",
    "    prices_df[\"E\"]=(pd.to_datetime(prices_df[\"E\"],unit='ms')) \n",
    "    prices_df.set_index(\"E\")\n",
    "    h = prices_df[prices_df[\"s\"].isin(coins)]\n",
    "   \n",
    "    h = h[h[\"E\"].dt.year==2021]\n",
    "    y =h.groupby([pd.Grouper(key ='E', freq='H'), \"s\"]).agg({'c': ['first', 'min', 'max', 'last']})\n",
    "\n",
    "    # rename columns\n",
    "    y.columns = ['c_first', 'c_min', 'c_max', 'c_last']\n",
    "\n",
    "    # reset index to get grouped columns back\n",
    "    y = y.reset_index()\n",
    "    return y\n",
    "\n",
    "# this function select a specific coin\n",
    "def select_coin(y, coin_name):\n",
    "\n",
    "    y1 = y[y[\"s\"] == coin_name]\n",
    "    y1b = y1[[\"E\", \"c_last\"]]\n",
    "    y1b= y1b.set_index(\"E\")\n",
    "    return y1b\n",
    "\n",
    "# check the stationarity of the cryptocurrency time series\n",
    "\n",
    "def adafuller(time_series):\n",
    "#h_diff = np.diff(h_log['score'])\n",
    "#h2 =  h2.groupby(pd.Grouper(freq='H')).score.sum()\n",
    "#h_diff = pd.DataFrame(h_diff, columns=['score'])\n",
    "#h1a_log2 = h1a_log.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "    result = adfuller(time_series)\n",
    "    #print('ADF Statistic: %f' % result[0])\n",
    "    print('p-value: %f' % result[1])\n",
    "    \n",
    "    #if result[1]<=0.05:\n",
    "    #    print('Time Series: stationary')\n",
    "    #else:\n",
    "    #    print('Time Series: non-stationary')    \n",
    "    return result[1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fractional differencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for finding thr weights\n",
    "    # return the weights from the series expansion of the differencing operator\n",
    "    # for real orders d and up to lags coefficients\n",
    "def getWeights(d,lags):\n",
    "    w=[1]\n",
    "    for k in range(1,lags):\n",
    "        w.append(-w[-1]*((d-k+1))/k)\n",
    "    w=np.array(w).reshape(-1,1) \n",
    "    return w\n",
    "def plotWeights(dRange, lags, numberPlots):\n",
    "    weights=pd.DataFrame(np.zeros((lags, numberPlots)))\n",
    "    interval=np.linspace(dRange[0],dRange[1],numberPlots)\n",
    "    for i, diff_order in enumerate(interval):\n",
    "        weights[i]=getWeights(diff_order,lags)\n",
    "    weights.columns = [round(x,2) for x in interval]\n",
    "    fig=weights.plot(figsize=(15,6))\n",
    "    plt.legend(title='Order of differencing')\n",
    "    plt.title('Lag coefficients for various orders of differencing')\n",
    "    plt.xlabel('lag coefficients')\n",
    "    #plt.grid(False)\n",
    "    plt.show()\n",
    "    \n",
    "# return the time series resulting from (fractional) differencing\n",
    "    # for real orders order up to lag_cutoff coefficients\n",
    "        \n",
    "def ts_differencing(series, order, lag_cutoff):\n",
    "\n",
    "    \n",
    "    weights=getWeights(order, lag_cutoff)\n",
    "    res=0\n",
    "    for k in range(lag_cutoff):\n",
    "        res += weights[k]*series.shift(k).fillna(0)\n",
    "    return res[lag_cutoff:] \n",
    "\n",
    "def cutoff_find(order,cutoff,start_lags): #order is our dearest d, cutoff is 1e-3 for us, and start lags is an initial amount of lags in which the loop will start, this can be set to high values in order to speed up the algo\n",
    "    val=np.inf\n",
    "    lags=start_lags\n",
    "    while abs(val)>cutoff:\n",
    "        w=getWeights(order, lags)\n",
    "        val=w[len(w)-1]\n",
    "        lags+=1\n",
    "    return lags\n",
    "\n",
    "def ts_differencing_tau(series, order, tau):\n",
    "    # return the time series resulting from (fractional) differencing\n",
    "    lag_cutoff=(cutoff_find(order,tau,1)) #finding lag cutoff with tau\n",
    "    weights=getWeights(order, lag_cutoff)\n",
    "    res=0\n",
    "    for k in range(lag_cutoff):\n",
    "        res += weights[k]*series.shift(k).fillna(0)\n",
    "    return res[lag_cutoff:] \n",
    "\n",
    "# function that find the d order of the functional differencing\n",
    "\n",
    "def find_fractional_d(y1b):\n",
    "    \n",
    "    #this part takes about 20 minutes to compute\n",
    "    possible_d=np.divide(range(1,100),100)\n",
    "    #print(possible_d)\n",
    "    tau=1e-3\n",
    "    original_adf_stat_holder=[None]*len(possible_d)\n",
    "    log_adf_stat_holder=[None]*len(possible_d)\n",
    "\n",
    "    for i in range(len(possible_d)):\n",
    "        original_adf_stat_holder[i]=adfuller(ts_differencing_tau(y1b,possible_d[i],tau))[1]\n",
    "        if original_adf_stat_holder[i]<=0.05:\n",
    "            print(possible_d[i], original_adf_stat_holder[i])\n",
    "            break;\n",
    "            \n",
    "    return possible_d[i]   \n",
    "\n",
    "#here we get 1e-3 as default, make the time series stationary\n",
    "def time_series_stationary(time_series,col):\n",
    "    if adafuller(time_series[col])>=0.05:\n",
    "        time_series[col] = ts_differencing_tau(time_series[col], find_fractional_d(time_series[col]), 1e-3)\n",
    "    return time_series\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply linear regression on random samples for evaluating the sentiment score relevance to the prices data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that finds the lagged values for the sentiment score\n",
    "def create_lagged_values_df(time_series, lag_num, score):\n",
    "    for i in range(1, lag_num):\n",
    "        time_series[\"score_lag\"+str(i)]=time_series[score].shift(i)\n",
    "      #  print(time_series)\n",
    "    return(time_series)\n",
    "\n",
    "\n",
    "# this function get a random sample from our prices and sentiment time series\n",
    "\n",
    "def get_random_sample(prices_ts, fract, sentiment_ts):\n",
    "    result2 = prices_ts.copy()\n",
    "    \n",
    "    prices_ts_sample=result2.sample(frac=fract)\n",
    "    price_merge_sent = pd.merge(prices_ts_sample, sentiment_ts, on='E', how = \"inner\")\n",
    "    price_merge_sent = price_merge_sent.dropna()\n",
    "   # print( price_merge_sent)\n",
    "    return price_merge_sent\n",
    "\n",
    "\n",
    "# Split the data in train and test and perform normalisation in our data\n",
    "def split_the_data(price_merge_sent, nobs):\n",
    "#nobs = 100\n",
    "    MINMAX_NORMALIZER = MinMaxScaler(feature_range=(-1, 1))\n",
    "    price_merge_sent_train, price_merge_sent_test = price_merge_sent[0:-nobs], price_merge_sent[-nobs:]\n",
    "   # print(price_merge_sent_train, price_merge_sent_test)\n",
    "# Check size\n",
    "#print(price_merge_sent_train.shape)  # (119, 8)\n",
    "#print(price_merge_sent_test.shape)  # (4, 8)\n",
    "    price_merge_sent_train_scaled = MINMAX_NORMALIZER.fit_transform(price_merge_sent_train.iloc[:,1:])\n",
    "                                                        # store the results in a data frame\n",
    "    price_merge_sent_train = pd.DataFrame(price_merge_sent_train_scaled, columns=price_merge_sent_train.iloc[:,1:].columns)\n",
    "    price_merge_sent_test_scaled = MINMAX_NORMALIZER.fit_transform(price_merge_sent_test.iloc[:,1:])\n",
    "    price_merge_sent_test = pd.DataFrame(price_merge_sent_test_scaled, columns=price_merge_sent_test.iloc[:,1:].columns)\n",
    "\n",
    "\n",
    "    return price_merge_sent_train, price_merge_sent_test\n",
    "\n",
    "\n",
    "\n",
    "def linear_regression(price_merge_sent_train, price_merge_sent_test):\n",
    "    regr = linear_model.LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "    regr.fit(price_merge_sent_train.iloc[:,2:], price_merge_sent_train.iloc[:,1])\n",
    "    print(price_merge_sent_train.iloc[:,2:], price_merge_sent_train.iloc[:,1])\n",
    "\n",
    "\n",
    "# Make predictions using the testing set\n",
    "    prices_y_pred = regr.predict(price_merge_sent_test.iloc[:,2:])\n",
    "\n",
    "# The coefficients\n",
    "    print('Coefficients: \\n', regr.coef_)\n",
    "# The mean squared error\n",
    "    print('Mean squared error: %.2f'\n",
    "      % mean_squared_error(price_merge_sent_test.iloc[:,1], prices_y_pred))\n",
    "# The coefficient of determination: 1 is perfect prediction\n",
    "    print('Coefficient of determination: %.2f'\n",
    "      % r2_score(price_merge_sent_test.iloc[:,1], prices_y_pred))\n",
    "    return prices_y_pred, mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "# this function performs linear regression on the random sampled price data\n",
    "def linear_regression1(price_merge_sent_train, price_merge_sent_test):\n",
    "    model1=sm.OLS(endog=price_merge_sent_train.iloc[:, 1],exog=price_merge_sent_train.iloc[:, 2:])\n",
    "    results1=model1.fit()\n",
    "    predictions = results1.predict(price_merge_sent_test.iloc[:,2:])\n",
    "    return results1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that does some preprocessing on price data like cleaning the specific coin and make the time series stationary\n",
    "\n",
    "def preprocess_coin(prices_df, coins, coin_name, col):\n",
    "    y = process_prices(prices_df,coins)\n",
    "    y = select_coin(y, coin_name)\n",
    "    y = time_series_stationary(y,col)\n",
    "    \n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y1_diff = preprocess_coin(prices_df, [\"BTCUSDT\", \"ETHUSDT\", \"ADAUSDT\", \"BNBUSDT\", \"USDTUSDT\", \"DOTUSDT\", \"XRPUSDT\", \"LTCUSDT\", \"LINKUSDT\", \"BCHUSDT\", \"XLMUSDT\"], \"BTCUSDT\", \"c_last\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the sentiment score without metadata\n",
    "def sentiment_score_calc(function, tweets_df, lag_num, score):\n",
    "    h = function(tweets_df)\n",
    "    h_new = process_score(h, score)\n",
    "    x1b_diff= time_series_stationary(h_new, \"score\")\n",
    "    x1b_with_lags = create_lagged_values_df(x1b_diff, lag_num, score)\n",
    "    return x1b_with_lags\n",
    "\n",
    "\n",
    "# calculate the sentiment score with metadata\n",
    "def final_sentiment_score_with_metadata(tweets_df, tweets_metadata_df, lag_num, score2):\n",
    "    tweets_df_merge =tweets_with_metadata(tweets_df, tweets_metadata_df)\n",
    "    tweets_df_merge[\"score2\"] =sent_score_metadata(tweets_df_merge)\n",
    "    h8 = aggr_score_metadata(tweets_df_merge)\n",
    "    h_new = process_score(h8, score2)\n",
    "    x1b_diff= time_series_stationary(h_new, \"score2\")\n",
    "    x1b_with_lags = create_lagged_values_df(x1b_diff, lag_num,score2)\n",
    "    return x1b_with_lags\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value: 0.024918\n",
      "p-value: 0.000000\n"
     ]
    }
   ],
   "source": [
    "#x1b_with_lags = sentiment_score_calc(aggr_score, tweets_df, 3)\n",
    "#x1b_with_lags2 = final_sentiment_score_with_metadata(tweets_df, tweets_metadata_df,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the function for evaluating with linear regression\n",
    "\n",
    "def evaluation_sentiment(prices_ts, sentiment_ts, fract, nobs):\n",
    "    price_merge_sent = get_random_sample(prices_ts, fract, sentiment_ts)\n",
    "    price_merge_sent_train, price_merge_sent_test = split_the_data(price_merge_sent, nobs)\n",
    "    results = linear_regression1(price_merge_sent_train, price_merge_sent_test)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluation_sentiment(y1_diff, x1b_with_lags, 0.6, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the function that runs the full pipeline with sentiment score without metadata\n",
    "def sent_price_eval1(prices_df,coins, coin_name, col, function, tweets_df, lag_num, fract, nobs, score):\n",
    "    y1_diff=preprocess_coin(prices_df, coins, coin_name, col)\n",
    "    x1b_with_lags = sentiment_score_calc(function, tweets_df, lag_num, score)\n",
    "    results = evaluation_sentiment(y1_diff, x1b_with_lags, fract, nobs)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the function that runs the full pipeline with sentiment score with metadata\n",
    "def sent_price_eval2(prices_df,coins, coin_name, col, tweets_df,tweets_metadata_df, lag_num, fract, nobs, score2):\n",
    "    y1_diff=preprocess_coin(prices_df, coins, coin_name, col)\n",
    "    x1b_with_lags = final_sentiment_score_with_metadata(tweets_df, tweets_metadata_df, lag_num, score2)\n",
    "    results = evaluation_sentiment(y1_diff, x1b_with_lags, fract, nobs)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value: 0.678634\n",
      "0.35 0.04852813177069784\n",
      "p-value: 0.020131\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>score</td>      <th>  R-squared (uncentered):</th>      <td>   0.945</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared (uncentered):</th> <td>   0.945</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>          <td>   3617.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 13 Jun 2021</td> <th>  Prob (F-statistic):</th>           <td>  0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>22:03:30</td>     <th>  Log-Likelihood:    </th>          <td>  201.46</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   631</td>      <th>  AIC:               </th>          <td>  -396.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   628</td>      <th>  BIC:               </th>          <td>  -383.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>              <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>              <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>score_lag1</th> <td>    1.2463</td> <td>    0.058</td> <td>   21.379</td> <td> 0.000</td> <td>    1.132</td> <td>    1.361</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>score_lag2</th> <td>   -0.5231</td> <td>    0.050</td> <td>  -10.391</td> <td> 0.000</td> <td>   -0.622</td> <td>   -0.424</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>score_lag3</th> <td>    0.2043</td> <td>    0.049</td> <td>    4.173</td> <td> 0.000</td> <td>    0.108</td> <td>    0.300</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>244.650</td> <th>  Durbin-Watson:     </th> <td>   1.964</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>33905.907</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.593</td>  <th>  Prob(JB):          </th> <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>38.892</td>  <th>  Cond. No.          </th> <td>    14.8</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                                 OLS Regression Results                                \n",
       "=======================================================================================\n",
       "Dep. Variable:                  score   R-squared (uncentered):                   0.945\n",
       "Model:                            OLS   Adj. R-squared (uncentered):              0.945\n",
       "Method:                 Least Squares   F-statistic:                              3617.\n",
       "Date:                Sun, 13 Jun 2021   Prob (F-statistic):                        0.00\n",
       "Time:                        22:03:30   Log-Likelihood:                          201.46\n",
       "No. Observations:                 631   AIC:                                     -396.9\n",
       "Df Residuals:                     628   BIC:                                     -383.6\n",
       "Df Model:                           3                                                  \n",
       "Covariance Type:            nonrobust                                                  \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "score_lag1     1.2463      0.058     21.379      0.000       1.132       1.361\n",
       "score_lag2    -0.5231      0.050    -10.391      0.000      -0.622      -0.424\n",
       "score_lag3     0.2043      0.049      4.173      0.000       0.108       0.300\n",
       "==============================================================================\n",
       "Omnibus:                      244.650   Durbin-Watson:                   1.964\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            33905.907\n",
       "Skew:                           0.593   Prob(JB):                         0.00\n",
       "Kurtosis:                      38.892   Cond. No.                         14.8\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calling the function price)eval1\n",
    "sent_price_eval1(prices_df, [\"BTCUSDT\", \"ETHUSDT\", \"ADAUSDT\", \"BNBUSDT\", \"USDTUSDT\", \"DOTUSDT\", \"XRPUSDT\", \"LTCUSDT\", \"LINKUSDT\", \"BCHUSDT\", \"XLMUSDT\"], \"XLMUSDT\", \"c_last\", aggr_neg_score, tweets_df, 4, 0.6, 100, \"score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value: 0.678634\n",
      "0.35 0.04852813177069784\n",
      "p-value: 0.000000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>score2</td>      <th>  R-squared (uncentered):</th>      <td>   0.606</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared (uncentered):</th> <td>   0.604</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>          <td>   319.8</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 13 Jun 2021</td> <th>  Prob (F-statistic):</th>          <td>1.25e-125</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>22:08:08</td>     <th>  Log-Likelihood:    </th>          <td>  709.23</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   626</td>      <th>  AIC:               </th>          <td>  -1412.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   623</td>      <th>  BIC:               </th>          <td>  -1399.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>              <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>              <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>score_lag1</th> <td>    0.1419</td> <td>    0.037</td> <td>    3.791</td> <td> 0.000</td> <td>    0.068</td> <td>    0.215</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>score_lag2</th> <td>    0.0764</td> <td>    0.043</td> <td>    1.764</td> <td> 0.078</td> <td>   -0.009</td> <td>    0.161</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>score_lag3</th> <td>    0.1649</td> <td>    0.010</td> <td>   16.910</td> <td> 0.000</td> <td>    0.146</td> <td>    0.184</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>632.494</td> <th>  Durbin-Watson:     </th>  <td>   2.007</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>285290.359</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 3.697</td>  <th>  Prob(JB):          </th>  <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>107.321</td> <th>  Cond. No.          </th>  <td>    7.34</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                                 OLS Regression Results                                \n",
       "=======================================================================================\n",
       "Dep. Variable:                 score2   R-squared (uncentered):                   0.606\n",
       "Model:                            OLS   Adj. R-squared (uncentered):              0.604\n",
       "Method:                 Least Squares   F-statistic:                              319.8\n",
       "Date:                Sun, 13 Jun 2021   Prob (F-statistic):                   1.25e-125\n",
       "Time:                        22:08:08   Log-Likelihood:                          709.23\n",
       "No. Observations:                 626   AIC:                                     -1412.\n",
       "Df Residuals:                     623   BIC:                                     -1399.\n",
       "Df Model:                           3                                                  \n",
       "Covariance Type:            nonrobust                                                  \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "score_lag1     0.1419      0.037      3.791      0.000       0.068       0.215\n",
       "score_lag2     0.0764      0.043      1.764      0.078      -0.009       0.161\n",
       "score_lag3     0.1649      0.010     16.910      0.000       0.146       0.184\n",
       "==============================================================================\n",
       "Omnibus:                      632.494   Durbin-Watson:                   2.007\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           285290.359\n",
       "Skew:                           3.697   Prob(JB):                         0.00\n",
       "Kurtosis:                     107.321   Cond. No.                         7.34\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calling the function price_eval2\n",
    "sent_price_eval2(prices_df, [\"BTCUSDT\", \"ETHUSDT\", \"ADAUSDT\", \"BNBUSDT\", \"USDTUSDT\", \"DOTUSDT\", \"XRPUSDT\", \"LTCUSDT\", \"LINKUSDT\", \"BCHUSDT\", \"XLMUSDT\"], \"XLMUSDT\", \"c_last\", tweets_df, tweets_metadata_df, 4, 0.6, 100, \"score2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
